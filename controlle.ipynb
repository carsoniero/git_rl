{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PolicyModel, Policy\n",
    "import torch\n",
    "from PPO import PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Инициализация модели\n",
    "from model import PolicyModel, Policy  # замените на ваш файл\n",
    "\n",
    "device = torch.device(\"cpu\")  # или \"cuda\"\n",
    "\n",
    "# Параметры\n",
    "action_dim = 2  # ax, ay\n",
    "state_dim = 12  # quadrotor state\n",
    "cmd_dim   = 2   # target command\n",
    "\n",
    "# Создаем сеть\n",
    "policy_net = PolicyModel(action_dim=action_dim, state_dim=state_dim, cmd_dim=cmd_dim)\n",
    "policy = Policy(policy_net, action_std=0.1, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEnv:\n",
    "    def reset(self):\n",
    "        obs_map = np.random.rand(36,36)\n",
    "        state   = np.random.rand(12)\n",
    "        cmd     = np.random.rand(2)\n",
    "        return obs_map, state, cmd\n",
    "\n",
    "    def step(self, action):\n",
    "        # Здесь action = np.array([ax, ay])\n",
    "        # Обновляем состояние, получаем награду\n",
    "        obs_map = np.random.rand(36,36)\n",
    "        state   = np.random.rand(12)\n",
    "        cmd     = np.random.rand(2)\n",
    "        reward = np.random.rand()\n",
    "        done = False\n",
    "        return (obs_map, state, cmd), reward, done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d597141",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyEnv()\n",
    "obs_map, state, cmd = env.reset()\n",
    "\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    # Получаем действие и value\n",
    "    output = policy.act(obs_map, state, cmd, training=False)\n",
    "    \n",
    "    action = output[\"actions\"]  # 1x2 → ax, ay\n",
    "    value  = output[\"values\"]\n",
    "\n",
    "    # Отправляем действие в среду\n",
    "    (obs_map, state, cmd), reward, done, info = env.step(action)\n",
    "\n",
    "    total_reward += reward\n",
    "\n",
    "print(\"Эпизод завершён, суммарная награда:\", total_reward)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
